{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Extraction and transformation data from gitHUB by gitHUB API.\n"
      ],
      "metadata": {
        "id": "0_mnoBurMkay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[Install extra library](#scrollTo=YmqZtuFVDKpJ)\n",
        "\n",
        ">[Import necessary libraries](#scrollTo=6cbXaYaPDOcZ)\n",
        "\n",
        ">[Authorization](#scrollTo=1bcx6Dv43kya)\n",
        "\n",
        ">[Rate limit](#scrollTo=9-9rL5nO8ec1)\n",
        "\n",
        ">>>[Control primary rate limit](#scrollTo=9-9rL5nO8ec1)\n",
        "\n",
        ">>>[Control secondary rate limit](#scrollTo=9-9rL5nO8ec1)\n",
        "\n",
        ">[Pagination](#scrollTo=bM0YMTqccpbi)\n",
        "\n",
        ">[Collection](#scrollTo=6whHRGT5Djsz)\n",
        "\n",
        ">>[Search repo](#scrollTo=Y1jAzGUmL13T)\n",
        "\n",
        ">>[Collect all commits by the repositories](#scrollTo=j4yADKNsBKP-)\n",
        "\n",
        ">>[Collect repo's content from main branch from main page](#scrollTo=l0cR_VFzhjCP)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "b6_820SfEXrK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install extra library"
      ],
      "metadata": {
        "id": "YmqZtuFVDKpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install extra library for auth\n",
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "T7cFJYB5u4OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary libraries"
      ],
      "metadata": {
        "id": "6cbXaYaPDOcZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gUj8pMb3MCln"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries\n",
        "import requests\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "import re\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Authorization\n",
        "\n",
        "Prepare .env file:<br>\n",
        "GITHUB-TOKEN=Bearer YOUR TOKEN<br>\n",
        "VERSION=API VERSION<br>\n",
        "- Bearer YOUR TOKEN -  that fine-grainted token. [Create token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens#creating-a-fine-grained-personal-access-token)\n",
        "- set the api version. [Supported version](https://docs.github.com/en/rest/about-the-rest-api/api-versions?apiVersion=2022-11-28#supported-api-versions)\n",
        "\n",
        "Save it in folder\n",
        "\n",
        "Check authorization using next"
      ],
      "metadata": {
        "id": "1bcx6Dv43kya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check .env file\n",
        "def check_auth_headers():\n",
        "    # load environment variables .env\n",
        "    load_dotenv(\".env\")\n",
        "\n",
        "    # Extract variables\n",
        "    api_token = os.getenv(\"GITHUB-TOKEN\")\n",
        "    api_version = os.getenv(\"VERSION\")\n",
        "    check_exist = 'You fill .env'\n",
        "    check_auth_headers_flag = True\n",
        "\n",
        "    if api_token is None or api_version is None:\n",
        "        check_exist = 'Error - you miss token or version, check .env'\n",
        "        check_auth_headers_flag = False\n",
        "\n",
        "    return check_exist, check_auth_headers_flag, api_token, api_version\n",
        "check_auth_headers()\n",
        "print(f'token - {check_auth_headers()[2]}', f'version - {check_auth_headers()[3]}', sep = '\\n')\n",
        "\n",
        "\n",
        "# Authenticating to the REST API\n",
        "def autorization():\n",
        "    if check_auth_headers()[1] is False:\n",
        "        return check_auth_headers()[0]\n",
        "\n",
        "    else:\n",
        "        url = \"https://api.github.com/octocat\"\n",
        "        headers = {\n",
        "        'Accept': 'application/vnd.github+json',\n",
        "        'Authorization': check_auth_headers()[2],\n",
        "        'X-GitHub-Api-Version': check_auth_headers()[3]\n",
        "        }\n",
        "        response = requests.request(\"GET\", url, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            return headers\n",
        "        else:\n",
        "            return print(f'Authentication failed. Status code: {response.status_code}')\n",
        "\n",
        "autorization()"
      ],
      "metadata": {
        "id": "U11yEAIPup-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rate limit\n",
        "- **Primary rate limit** <br>\n",
        "for personal autherisation users 5000 requests per hour. <br>[Check](https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api?apiVersion=2022-11-28#primary-rate-limit-for-authenticated-users)\n",
        "- **Secondary rate limit**\n",
        "-- No more than 100 concurrent requests are allowed\n",
        "-- No more than 900 points per minute are allowed for REST API endpoints\n",
        "-- No more than 90 seconds of CPU time per 60 seconds of real time is allowed.\n",
        "-- Make too many requests that consume excessive computing resources in a short period of time.<br>\n",
        "[Check](https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api?apiVersion=2022-11-28#about-secondary-rate-limits)\n",
        "\n",
        "### Control primary rate limit\n",
        "-- x-ratelimit-remaining header from response should be more then 0\n",
        "-- when x-ratelimit-remaining header is 0, the next request should be after x-ratelimit-reset time\n",
        "\n",
        "### Control secondary rate limit\n",
        "-- If the retry-after response header is present, you should not retry your request until after that many seconds has elapsed."
      ],
      "metadata": {
        "id": "9-9rL5nO8ec1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pagination\n",
        "- Some endpoints have the pagination.<br>\n",
        "If the endpoint has the page parameter in response headers you find the header [Link](https://docs.github.com/en/rest/using-the-rest-api/using-pagination-in-the-rest-api?apiVersion=2022-11-28)\n",
        "-- page - just the current page number\n",
        "-- per_page - number of objects per page will returned"
      ],
      "metadata": {
        "id": "bM0YMTqccpbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collection"
      ],
      "metadata": {
        "id": "6whHRGT5Djsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Search repo\n",
        "- 30 per page\n",
        "- 30 request fine-granted\n",
        "- serch only by name\n",
        "- exrtact the owner login and repo names"
      ],
      "metadata": {
        "id": "Y1jAzGUmL13T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the prompt for searching repo\n",
        "max_length = 256\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Type prompt (less than 256 symbols): \")\n",
        "    if len(user_input) <= max_length:\n",
        "        break\n",
        "    else:\n",
        "        print(f\"Too long! Max length â€” {max_length}. Repeat.\")\n",
        "\n",
        "\n",
        "url = f'https://api.github.com/search/repositories?q={user_input} in:name'\n",
        "all_results = []  # List of result\n",
        "payload = {}\n",
        "headers = autorization()\n",
        "\n",
        "# Set the request limit\n",
        "requests_per_hour = 5000  # max request per hour for auth user\n",
        "time_between_requests = 3600 / requests_per_hour  # time interval between requests\n",
        "secondary_rate_limit_wait = 60 # waiting time in secondary rate limit reach\n",
        "\n",
        "while url:\n",
        "    print(f'url:{url}') # checking url and pagination in url\n",
        "    response = requests.get(url, headers=headers, data=payload)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        all_results.extend(data.get(\"items\", []))  # add the current page result\n",
        "\n",
        "        # Check next page if exists\n",
        "        link_header = response.headers.get(\"Link\", \"\")\n",
        "\n",
        "        if 'rel=\"next\"' in link_header:\n",
        "            # Check the next page to see if it exists\n",
        "            pattern = r'<.*?page=(\\d+)>; rel=\"next\"'\n",
        "            match = re.search(pattern, link_header)\n",
        "            last_page = f'&page={match.group(1)}'\n",
        "\n",
        "            url = f'{url.split(\"&page\")[0]}{last_page}'\n",
        "\n",
        "        else:\n",
        "            url = None  # if next page doesn't exist\n",
        "        time.sleep(time_between_requests) #timebrake between requests\n",
        "\n",
        "    # handling 403 and 429 errors\n",
        "    elif response.status_code == 403 or response.status_code == 429:\n",
        "        # Check Secondary Rate Limit\n",
        "        if 'Retry-After' in response.headers:\n",
        "            print(f\"Secondary rate limit reached. Waiting for {secondary_rate_limit_wait} seconds...\")\n",
        "            time.sleep(secondary_rate_limit_wait)\n",
        "            continue\n",
        "        # Check Primary Rate Limit\n",
        "        if 'X-RateLimit-Remaining' in response.headers:\n",
        "            remaining = int(response.headers['X-RateLimit-Remaining'])\n",
        "            if remaining == 0:\n",
        "                reset_time = int(response.headers['X-RateLimit-Reset'])\n",
        "                wait_time = reset_time - int(time.time())\n",
        "                print(f\"Primary rate limit reached. Waiting for {wait_time} seconds...\")\n",
        "                time.sleep(wait_time + 1)\n",
        "                continue\n",
        "\n",
        "    # handling others's errors\n",
        "    else:\n",
        "        error_message = response.json().get(\"message\", \"No error message provided\")\n",
        "        print(f\"Error: {response.status_code} {error_message}\")\n",
        "        break\n",
        "# extraction repo's name and repo's owner\n",
        "repo_list = [[i['name'], i['owner']['login']] for i in all_results]"
      ],
      "metadata": {
        "id": "p5CW6MPbhNl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collect all commits by the repositories\n",
        "- repo_list - the list with all founded repos and owners."
      ],
      "metadata": {
        "id": "j4yADKNsBKP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_commits = []\n",
        "commit_data_list = []\n",
        "for i in repo_list:\n",
        "    repo_name = i[0]\n",
        "    owner_name = i[1]\n",
        "    url = f'https://api.github.com/repos/{owner_name}/{repo_name}/commits'\n",
        "\n",
        "    while url:\n",
        "        print(url)\n",
        "        response = requests.get(url, headers=headers, data=payload)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                for j in range(len(data)):\n",
        "                    commit_author = data[j]['commit']['committer']['name']\n",
        "                    commit_date = data[j]['commit']['committer']['date']\n",
        "                    commit_message = data[j]['commit']['message']\n",
        "                    commit_data_list.append({\n",
        "                        'owner': owner_name,\n",
        "                        'repository': repo_name,\n",
        "                        'commit_author': commit_author,\n",
        "                        'commit_date': commit_date,\n",
        "                        'commit_message': commit_message\n",
        "                    })\n",
        "                    #print(repo_name,owner_name, commit_author,  commit_date, commit_message)\n",
        "                all_commits.extend(data)\n",
        "                link_header = response.headers.get(\"Link\", \"\")\n",
        "\n",
        "                if 'rel=\"next\"' in link_header:\n",
        "                    # Change link for next page\n",
        "                    pattern = r'<.*?page=(\\d+)>; rel=\"next\"'\n",
        "                    match = re.search(pattern, link_header)\n",
        "                    last_page = f'?page={match.group(1)}'\n",
        "\n",
        "                    url = f'{url.split(\"?page\")[0]}{last_page}'\n",
        "\n",
        "                else:\n",
        "                    url = None  # if next page doesn't exist\n",
        "\n",
        "        # handling 403 and 429 errors\n",
        "        elif response.status_code == 403 or response.status_code == 429:\n",
        "            # Check Secondary Rate Limit\n",
        "            if 'Retry-After' in response.headers:\n",
        "                print(f\"Secondary rate limit reached. Waiting for {secondary_rate_limit_wait} seconds...\")\n",
        "                time.sleep(secondary_rate_limit_wait)\n",
        "                continue\n",
        "            # Check Primary Rate Limit\n",
        "            if 'X-RateLimit-Remaining' in response.headers:\n",
        "                remaining = int(response.headers['X-RateLimit-Remaining'])\n",
        "                if remaining == 0:\n",
        "                    reset_time = int(response.headers['X-RateLimit-Reset'])\n",
        "                    wait_time = reset_time - int(time.time())\n",
        "                    print(f\"Primary rate limit reached. Waiting for {wait_time} seconds...\")\n",
        "                    time.sleep(wait_time + 1)\n",
        "                    continue\n",
        "        # handling others's errors\n",
        "        else:\n",
        "            error_message = response.json().get(\"message\", \"No error message provided\")\n",
        "            print(f\"Error: {response.status_code} {error_message}\")\n",
        "            break\n",
        "\n",
        "\n",
        "# Transform to df, clean from NULL, save as .csv\n",
        "if commit_data_list == []:\n",
        "    print(f'{user_input} repository does not found')\n",
        "else:\n",
        "    commits_df = pd.DataFrame(commit_data_list)\n",
        "    commits_df.dropna(subset =['commit_message'], inplace = True)\n",
        "    commits_df.to_csv('Commit_list.csv')\n",
        "    commits_df.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LA2xUcTzBlHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collect repo's content from main branch from main page"
      ],
      "metadata": {
        "id": "l0cR_VFzhjCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_content = []\n",
        "content_data_list = []\n",
        "for i in repo_list:\n",
        "    repo_name = i[0]\n",
        "    owner_name = i[1]\n",
        "    url = f'https://api.github.com/repos/{owner_name}/{repo_name}/contents'\n",
        "    response = requests.get(url, headers=headers, data=payload)\n",
        "    if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            for j in range(len(data)):\n",
        "                content_name = data[j]['name']\n",
        "                content_path = data[j]['path']\n",
        "                content_size = data[j]['size']\n",
        "                content_type = data[j]['type']\n",
        "                content_data_list.append({\n",
        "                    'owner': owner_name,\n",
        "                    'repository': repo_name,\n",
        "                    'content_name': content_name,\n",
        "                    'content_path': content_path,\n",
        "                    'content_size': content_size,\n",
        "                    'content_type': content_type\n",
        "                })\n",
        "                #print(repo_name,owner_name, content_name,  content_path, content_size, content_type)\n",
        "            all_content.extend(data)\n",
        "\n",
        "\n",
        "    elif response.status_code == 403 or response.status_code == 429:\n",
        "        # Check Secondary Rate Limit\n",
        "        if 'Retry-After' in response.headers:\n",
        "            #print(f\"Secondary rate limit reached. Waiting for {secondary_rate_limit_wait} seconds...\")\n",
        "            time.sleep(secondary_rate_limit_wait)\n",
        "            continue\n",
        "        # Check Primary Rate Limit\n",
        "        if 'X-RateLimit-Remaining' in response.headers:\n",
        "            remaining = int(response.headers['X-RateLimit-Remaining'])\n",
        "            if remaining == 0:\n",
        "                reset_time = int(response.headers['X-RateLimit-Reset'])\n",
        "                wait_time = reset_time - int(time.time())\n",
        "                print(f\"Primary rate limit reached. Waiting for {wait_time} seconds...\")\n",
        "                time.sleep(wait_time + 1)\n",
        "                continue\n",
        "    else:\n",
        "        error_message = response.json().get(\"message\", \"No error message provided\")\n",
        "        print(f\"Error: {response.status_code} {error_message}\")\n",
        "        continue\n",
        "\n",
        "\n",
        "# Transform to df, clean from NULL, save as .csv\n",
        "if content_data_list == []:\n",
        "    print(f'{user_input} repository does not found')\n",
        "else:\n",
        "    content_df = pd.DataFrame(content_data_list)\n",
        "    content_df.dropna(subset =['content_path', 'content_size', 'content_type'], inplace = True)\n",
        "    content_df.info()\n",
        "    content_df.to_csv('Content_list.csv')"
      ],
      "metadata": {
        "id": "zTWi2Mzjh_Hb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}